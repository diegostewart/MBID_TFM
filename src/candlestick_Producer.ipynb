{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO RUN THIS NOTEBOOK YOU NEED TO HAVE STARTED Zookeeper and Kafka\n",
    "#OPEN 2 GIT BASH CONSOLES AND RUN ()\n",
    "# context/kafka/bin/zookeeper-server-start.sh context/kafka/config/zookeeper.properties\n",
    "# context/kafka/bin/kafka-server-start.sh context/kafka/config/server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from cassandra.cluster import Cluster\n",
    "import json\n",
    "import time\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pandas as pd\n",
    "\n",
    "#################################################################################################\n",
    "# OPEN 2 GIT BASH CONSOLES AND RUN ()\n",
    "# context/kafka/bin/zookeeper-server-start.sh context/kafka/config/zookeeper.properties\n",
    "# context/kafka/bin/kafka-server-start.sh context/kafka/config/server.properties\n",
    "#################################################################################################\n",
    "\n",
    "# Set up Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092',\n",
    "                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "# Set up Cassandra connection\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()\n",
    "session.set_keyspace('dmsb_tfm')\n",
    "\n",
    "# Initialize variable to store the timestamp or identifier of the last processed row\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Execute Cassandra query\n",
    "        query = \"SELECT * FROM configuration LIMIT 1\"\n",
    "        result = session.execute(query)\n",
    "        # Retrieve values from the first row\n",
    "        for row in result:\n",
    "            symbol = row.symbol\n",
    "            candle_number = row.candle_number\n",
    "            ARIMA_p = row.arima_p\n",
    "            ARIMA_d = row.arima_d\n",
    "            ARIMA_q = row.arima_q\n",
    "\n",
    "        query = \"SELECT * FROM candlesticks LIMIT 5000\"\n",
    "        result = session.execute(query)\n",
    "        rows = [row._asdict() for row in result]\n",
    "\n",
    "        # This is the df from our table. It is ordered by event_time as designed in cassandra\n",
    "        df_candlesticks = pd.DataFrame(rows)\n",
    "        df_candlesticks = df_candlesticks.sort_values(by='start_time', ascending=True)\n",
    "\n",
    "        # We get the time used for the prediction:\n",
    "        df_prediction_start_time = df_candlesticks['start_time']\n",
    "        df_prediction_symbol = df_candlesticks['symbol']\n",
    "\n",
    "        prediction_start_time = df_prediction_start_time.iloc[-1]\n",
    "        prediction_symbol = df_prediction_symbol.iloc[-1]\n",
    "\n",
    "        # Filter only the ended candles to permorm our model\n",
    "        df_kline_closed = df_candlesticks[df_candlesticks['kline_closed'] == True]\n",
    "\n",
    "        # Used to limit the amount of rows applied to ARIMA\n",
    "        df_kline_closed = df_kline_closed.tail(candle_number)\n",
    "\n",
    "        # Create our each df\n",
    "        df_close = df_kline_closed[['start_time', 'close']]\n",
    "        df_open = df_kline_closed[['start_time', 'open']]\n",
    "        df_high = df_kline_closed[['start_time', 'high']]\n",
    "        df_low = df_kline_closed[['start_time', 'low']]\n",
    "\n",
    "        # Create the ARIMA model\n",
    "        close_model = ARIMA(df_close['close'].tolist(), order=(ARIMA_p, ARIMA_d, ARIMA_q))\n",
    "        open_model = ARIMA(df_open['open'].tolist(), order=(ARIMA_p, ARIMA_d, ARIMA_q))\n",
    "        high_model = ARIMA(df_high['high'].tolist(), order=(ARIMA_p, ARIMA_d, ARIMA_q))\n",
    "        low_model = ARIMA(df_low['low'].tolist(), order=(ARIMA_p, ARIMA_d, ARIMA_q))\n",
    "\n",
    "        # Fit the model\n",
    "        close_model_fit = close_model.fit()\n",
    "        open_model_fit = open_model.fit()\n",
    "        high_model_fit = high_model.fit()\n",
    "        low_model_fit = low_model.fit()\n",
    "\n",
    "        # Get our predictions.\n",
    "        close_prediction = close_model_fit.forecast()[0]\n",
    "        open_prediction = open_model_fit.forecast()[0]\n",
    "        high_prediction = high_model_fit.forecast()[0]\n",
    "        low_prediction = low_model_fit.forecast()[0]\n",
    "\n",
    "        # Send data to Kafka topic\n",
    "        # Convert row to a dictionary (or any format suitable for your use case)\n",
    "        message = {'symbol':prediction_symbol,'start_time': str(prediction_start_time), 'open': open_prediction,\n",
    "                    'high': high_prediction, 'low': low_prediction, 'close': close_prediction}\n",
    "\n",
    "        # Send the message to Kafka topic\n",
    "        \n",
    "        try:\n",
    "            producer.send('candlestickStream', value=message)\n",
    "            # print(message)\n",
    "        except Exception as e:\n",
    "            print(f'Error sending message: {e}')\n",
    "\n",
    "        # Flush messages to ensure they are sent immediately\n",
    "        producer.flush()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Close connections if the program is terminated by a keyboard interrupt (Ctrl+C)\n",
    "    producer.close()\n",
    "    session.shutdown()\n",
    "    cluster.shutdown()\n",
    "    print('All connections have been closed')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
